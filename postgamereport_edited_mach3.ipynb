{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6532d0",
   "metadata": {},
   "source": [
    "Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0742f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import shutil\n",
    "from tkinter import filedialog\n",
    "from tkinter import Tk\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e914433",
   "metadata": {},
   "source": [
    "Methods from original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83530ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_file():\n",
    "    # Create and withdraw root window\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # we don't want a full GUI, so keep the root window from appearing\n",
    "\n",
    "    # Print a message before showing the file dialog\n",
    "    print(\"Opening file dialog...\")\n",
    "\n",
    "    # Show an \"Open\" dialog box and return the path to the selected file\n",
    "    filepath = filedialog.askopenfilename()\n",
    "\n",
    "    # Ensure the Tkinter instance is destroyed after use\n",
    "    # This should help to ensure that you can re-run the code in case it doesn't work\n",
    "    root.destroy()\n",
    "\n",
    "    # Print the selected file path to confirm\n",
    "    print(f\"Selected file: {filepath}\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "#edited to return boolean\n",
    "def two_three_success(group):\n",
    "    if any(group.iloc[:3]['PitchCall'] == 'HitByPitch'):\n",
    "        return True\n",
    "    if len(group) < 4:\n",
    "        if len(group) >= 3 and group.iloc[2]['Balls'] == 2 and group.iloc[2]['PitchCall'] == 'InPlay':\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    return(len(group) >= 4 and group.iloc[3]['Strikes'] == 2)\n",
    "   \n",
    "    \n",
    "#edited to return boolean\n",
    "def ab_eff_success(group):\n",
    "    return (len(group) <= 4)\n",
    "    \n",
    "\n",
    "def home_plate_drawing(ax4):\n",
    "    ax4.plot([-0.708, 0.708], [0.15, 0.15], color='black', linewidth=1)\n",
    "    ax4.plot([-0.708, -0.708], [0.15, 0.3], color='black', linewidth=1)\n",
    "    ax4.plot([-0.708, 0], [0.3, 0.5], color='black', linewidth=1)\n",
    "    ax4.plot([0, 0.708], [0.5, 0.3], color='black', linewidth=1)\n",
    "    ax4.plot([0.708, 0.708], [0.3, 0.15], color='black', linewidth=1)\n",
    "    \n",
    "def define_zone(height):\n",
    "    if height > 2.2:\n",
    "        return 'upper'\n",
    "    elif 1.9 <= height <= 2.2:\n",
    "        return 'middle'\n",
    "    elif 0.0 <= height < 1.9:\n",
    "        return 'low'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f477c0ea",
   "metadata": {},
   "source": [
    "constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6724194",
   "metadata": {},
   "outputs": [],
   "source": [
    "PITCH_COLORS = {\n",
    "    'Fastball': '#d22d49',\n",
    "    'Fastballs': '#d22d49',\n",
    "    'FourSeamFastBall': '#d22d49',\n",
    "    'TwoSeamFastBall': '#de6a04',\n",
    "    'Two-Seam': '#de6a04',\n",
    "    'Sinker': '#de6a04',\n",
    "    'Cutter': '#933f2c',\n",
    "    'Slider': '#eee716',\n",
    "    'Split-Finger': '#3bacac',\n",
    "    'Splitter': '#3bacac',\n",
    "    'ChangeUp': '#1dbe3a',\n",
    "    'Sweeper': '#ddb33a',\n",
    "    'Curveball': '#00d1ed',\n",
    "    'Other': '#888888'\n",
    "}\n",
    "ZONE_BOUNDS = {\n",
    "    'min_plate_x': -0.81,\n",
    "    'max_plate_x': 0.81,\n",
    "    'min_plate_z': 1.69,\n",
    "    'max_plate_z': 3.14\n",
    "}\n",
    "PITCH_TYPE_MAPPING = {\n",
    "    'Splitter': 'ChangeUp', \n",
    "    'Fastball': 'Fastball', \n",
    "    'FourSeamFastBall': 'Fastball', \n",
    "    'TwoSeamFastBall': 'Fastball', \n",
    "    'Sinker': 'Fastball', \n",
    "    'Cutter': 'Fastball'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decac80a",
   "metadata": {},
   "source": [
    "Method for checking if pitch was in zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a7ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_zone(df):\n",
    "    return (\n",
    "        (ZONE_BOUNDS['min_plate_x'] <= df['PlateLocSide'] <= ZONE_BOUNDS['max_plate_x']) &\n",
    "        (ZONE_BOUNDS['min_plate_z'] <= df['PlateLocHeight'] <= ZONE_BOUNDS['max_plate_z'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6719c",
   "metadata": {},
   "source": [
    "method for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a598827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(dtype_dict):\n",
    "    #filepath = select_file()\n",
    "    filepath = r'C:\\Users\\gavin\\Au_Baseball\\TrackMan_SMML_Master_CSV.csv'\n",
    "    df = pd.read_csv(filepath, usecols = range(92), dtype=dtype_dict, parse_dates=['Date'])\n",
    "    \n",
    "    #sets dataframe to only take from auburn pitchers\n",
    "    mask = ((df['PitcherTeam'].isin(['AUB_TIG', 'AUB_PRC', 'AUB'])))\n",
    "    df = df.loc[mask]\n",
    "    \n",
    "     #rename columns\n",
    "    df = df.rename(columns={'Top/Bottom': 'Top.Bottom', \n",
    "                            'RelSpeed': 'Velo', \n",
    "                            'HorzBreak': 'HB', \n",
    "                            'SpinRate': 'Spin',\n",
    "                           'RelSpeed_mean': 'Velo_mean', \n",
    "                              'RelSpeed_max': 'Velo_max',\n",
    "                              'RelSpeed_min': 'Velo_min',\n",
    "                              'HorzBreak_mean': 'HB_mean',\n",
    "                              'HorzBreak_max': 'HB_max',\n",
    "                              'HorzBreak_min': 'HB_min',\n",
    "                              'SpinRate_mean': 'Spin_mean',\n",
    "                              'SpinRate_max': 'Spin_max',\n",
    "                              'SpinRate_min': 'Spin_min',\n",
    "                           'InducedVertBreak': 'IVB'}\n",
    "                  )\n",
    "    \n",
    "    df['in_zone'] = df.apply(is_in_zone, axis = 1)\n",
    "    df['GeneralPitchType'] = df['TaggedPitchType'].map(PITCH_TYPE_MAPPING).fillna(df['TaggedPitchType'])\n",
    "   \n",
    "    # Ensure 'Date' column is in string format to avoid datetime reduction errors\n",
    "    df['Date'] = df['Date'].astype(str)\n",
    "    \n",
    "    # Create a unique identifier for each plate appearance\n",
    "    df['PlateAppearanceID'] = df['Date'] + \"_\" + df['Pitcher'] + \"_\" + df['Top.Bottom'] + \"_\" + df['Inning'].astype(str) + \"_\" + df['PAofInning'].astype(str)\n",
    "    \n",
    "    plate_appearance_grouped = df.groupby('PlateAppearanceID')\n",
    "    tts = plate_appearance_grouped.apply(two_three_success).reset_index().rename(columns={0: 'two_three_success'})\n",
    "    aes = plate_appearance_grouped.apply(ab_eff_success).reset_index().rename(columns={0: 'ab_eff_success'})\n",
    "    df = pd.merge(df, tts, on='PlateAppearanceID', how='left')\n",
    "    df = pd.merge(df, aes, on='PlateAppearanceID', how='left')\n",
    "    \n",
    "    #...then convert 'Date' column back to datetime format for later\n",
    "    #df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    \n",
    "    #vertical approach angle recalculated (from original file)\n",
    "    df['nVAA'] = df['VertApprAngle'] - (-13.73 + (df['Velo'] * 0.06312) + ((df['PlateLocHeight'] * 1.067)))\n",
    "    \n",
    "    # Map the 'TaggedPitchType' column using the pitch mapping dictionary\n",
    "    df['GeneralPitchType'] = df['TaggedPitchType'].map(PITCH_TYPE_MAPPING).fillna(df['TaggedPitchType'])\n",
    "\n",
    "\n",
    "    # Create a new column 'PitchCount' that represents the pitch count for each pitcher\n",
    "    df['PitchCount'] = df.groupby(['Pitcher','TaggedPitchType']).cumcount() + 1\n",
    "\n",
    "    # Define the pitch calls that indicate a swing\n",
    "    swing_calls = ['StrikeSwinging', 'InPlay', 'FoulBallNotFieldable', 'FoulBall', 'FoulBallFieldable']\n",
    "\n",
    "    # Create a new 'Swing' column\n",
    "    df['Swing'] = df['PitchCall'].isin(swing_calls)\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a679a9",
   "metadata": {},
   "source": [
    "method to calculate first set of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd49a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics1(df):\n",
    "    # Initialize an empty DataFrame to store the metrics for each pitcher\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    # Initialize an empty list to store the metrics for each pitcher\n",
    "    metrics_list = []\n",
    "\n",
    "    # Iterate over each unique pitcher\n",
    "    for pitcher in df['Pitcher'].unique():\n",
    "        # Filter the DataFrame for the current pitcher\n",
    "        df_pitcher = df[df['Pitcher'] == pitcher]\n",
    "    \n",
    "        # Calculate the metrics for the current pitcher\n",
    "        FPS = ((df_pitcher['PitchofPA'] == 2) & (df_pitcher['Strikes'] == 1)).mean() * 100\n",
    "    \n",
    "        # Calculate the number of plate appearances that ended in a walk\n",
    "        \n",
    "        walks = df_pitcher.groupby('PlateAppearanceID').apply(lambda group: 1 if group['KorBB'].iloc[-1] == 'Walk' else 0).sum()\n",
    "    \n",
    "        # Calculate the total number of plate appearances\n",
    "        total_plate_appearances = df_pitcher['PlateAppearanceID'].nunique()\n",
    "    \n",
    "        # Calculate BB%\n",
    "        BB_percentage = (walks / total_plate_appearances) * 100 if total_plate_appearances != 0 else 0\n",
    "    \n",
    "        two_thirds = (df_pitcher.groupby('PlateAppearanceID')['two_three_success'].first() == \"success\").mean() * 100\n",
    "        AB_Efficiency = (df_pitcher.groupby('PlateAppearanceID')['ab_eff_success'].first() == \"success\").mean() * 100\n",
    "    \n",
    "        Zone_percentage = df_pitcher[~((df_pitcher['Strikes'] == 2) & (df_pitcher['Balls'] <= 1))]['in_zone'].mean() * 100\n",
    "    \n",
    "        # Calculate Zone% for each pitch type for the current pitcher\n",
    "        pitch_type_metrics = {}\n",
    "        for pitch_type in df_pitcher['GeneralPitchType'].unique():\n",
    "            pitch_type_metrics[f'{pitch_type}_Zone%'] = round(df_pitcher[(df_pitcher['GeneralPitchType'] == pitch_type) & ~((df_pitcher['Strikes'] == 2) & (df_pitcher['Balls'] <= 1))]['in_zone'].mean() * 100, 2)\n",
    "    \n",
    "        # Append the metrics for the current pitcher to the list\n",
    "        metrics_list.append(pd.Series({'FPS': FPS, '2/3': two_thirds, 'AB Efficiency': AB_Efficiency, 'BB%': BB_percentage, 'Zone%': Zone_percentage, **pitch_type_metrics}, name=pitcher))\n",
    "\n",
    "    # Convert the list of metrics to a DataFrame\n",
    "    metrics = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Replace NaN values with '-'\n",
    "    metrics.fillna('-', inplace=True)\n",
    "\n",
    "    metrics = metrics.round(2)\n",
    "    # Sort the DataFrame by index\n",
    "    metrics = metrics.sort_index()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e3b622",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot perform reduction 'sum' with string dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(dtype_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNotes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m----> 2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m metrics1(df)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m, in \u001b[0;36mmetrics1\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     14\u001b[0m FPS \u001b[38;5;241m=\u001b[39m ((df_pitcher[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPitchofPA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_pitcher[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrikes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the number of plate appearances that ended in a walk\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m walks \u001b[38;5;241m=\u001b[39m df_pitcher\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlateAppearanceID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m group: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKorBB\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWalk\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate the total number of plate appearances\u001b[39;00m\n\u001b[0;32m     20\u001b[0m total_plate_appearances \u001b[38;5;241m=\u001b[39m df_pitcher[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlateAppearanceID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11512\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11493\u001b[0m \u001b[38;5;129m@doc\u001b[39m(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m  11494\u001b[0m     _num_doc,\n\u001b[0;32m  11495\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the sum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11510\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11511\u001b[0m ):\n\u001b[1;32m> 11512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, min_count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11280\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[0;32m  11273\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11274\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11278\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11279\u001b[0m ):\n\u001b[1;32m> 11280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_count_stat_function(\n\u001b[0;32m  11281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnansum, axis, skipna, numeric_only, min_count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11282\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11263\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  11261\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_axis_number\n\u001b[1;32m> 11263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11264\u001b[0m     func,\n\u001b[0;32m  11265\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m  11266\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m  11267\u001b[0m     skipna\u001b[38;5;241m=\u001b[39mskipna,\n\u001b[0;32m  11268\u001b[0m     numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m  11269\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m  11270\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10515\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  10517\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  10518\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 10519\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  10520\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10480\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  10476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m  10477\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr, ArrayManager\n\u001b[0;32m  10478\u001b[0m     ):\n\u001b[0;32m  10479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m> 10480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m  10481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\string_.py:476\u001b[0m, in \u001b[0;36mStringArray._reduce\u001b[1;34m(self, name, skipna, axis, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)(skipna\u001b[38;5;241m=\u001b[39mskipna, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m--> 476\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot perform reduction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with string dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot perform reduction 'sum' with string dtype"
     ]
    }
   ],
   "source": [
    "df = load_and_preprocess_data(dtype_dict = {'Notes': 'string'})\n",
    "metrics = metrics1(df)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132cad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
